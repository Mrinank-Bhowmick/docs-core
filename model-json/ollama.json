{
  "provider": {
    "name": "Ollama",
    "imageUrl": "",
    "description": "Integrate your locally hosted models on Ollama with Portkey",
    "website": "https://ollama.com",
    "slug": "ollama",
    "mostCommonModels": [],
    "uptimeLatencyChartsLink": "",
    "discordCommunityLink": "https://portkey.ai/community",
    "pricingLink": "",
    "documentationLink": "https://ollama.com/library"
  },
  "supported": {
    "models": [
      {
        "title": "Chat",
        "description": "Portkey supports Ollama Chat API.",
        "supportedModels": [
          "Llama 3.1",
          "Phi 3",
          "Gemma",
          "Mistral",
          "Moondream",
          "Code Llama",
          "LlaVa"
        ],
        "moreModels": "https://github.com/ollama/ollama?tab=readme-ov-file#model-library"
      }
    ],
    "notSupported": [
    {
      "promptPlayground": "Prompt playground is not supported for Ollama models",
      "parameters": []
    },
    {
    "models":
      {
        "title":"Generate",
        "description":"Portkey does not support Ollama's models on the /generate route"
      }
    }
    ]
  },
    "integration": {
      "chatCompletionsCall": {
        "portkeyPythonSDK": {
          "description": "Use Portkey Python SDK to make chat calls to Ollama chat completions models",
          "codeExample": "sample python code for llama-3.1 chat call on Ollama"
        },
        "portkeyNodeSDK": {
          "description": "Use Portkey Node.js SDK to make chat calls to Ollama chat completions models",
          "codeExample": "sample node.js code for llama-3.1 chat call on Ollama"
        },
        "restAPI": {
          "description": "Use Portkey's REST API to make chat calls to Ollama chat completions models",
          "codeExample": "sample rest api code for llama-3.1 chat call on Ollama"
        },
        "openAIPythonSDK": {
          "description": "Use OpenAI Python SDK to make chat calls to Ollama chat completions models",
          "codeExample": "sample openai SDK python code for llama-3.1 chat call on Ollama"
        },
        "openAINodeSDK": {
          "description": "Use OpenAI Node.js SDK to make chat calls to Ollama chat completions models",
          "codeExample": "sample openai SDK node.js code for llama-3.1 chat call on Ollama"
        }
      },
      "integrationViaVirtualKey": {
        "description": "",
        "generateVirtualKey": {
          "inline": {
            "text": "",
            "screenshot": "",
            "description": ""
          }
        }
      },
      "promptPlayground": {
        "description": "Coming soon.."
      }
    },
    "specialExamples": [],
    "portkeyCapabilities": [
      {
        "title": "Configure Routing",
        "description": "Configure routing for your Cerebras requests",
        "link": "/docs/product/ai-gateway/routing"
      },
      {
        "title": "Add Metadata to Requests",
        "description": "Add metadata to your Cerebras requests",
        "link": "/docs/product/observability/metadata"
      },
      {
        "title": "A/B Test Different Models",
        "description": "A/B test different models",
        "link": "/docs/product/ai-gateway/load-balance"
      },
      {
        "title": "Gain Insights to Requests",
        "description": "Gain insights to your Cerebras requests",
        "link": "/docs/product/observability/traces"
      }
    ],
    "useCases": [],
    "additionalInfo": []
  }
}
