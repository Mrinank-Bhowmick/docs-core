{
  "provider": {
    "name": "Local AI",
    "imageUrl": "",
    "description": "Local AI lets you run over 379 open source chat, image, audio models locally with a drop-in replacement for the OpenAI API.",
    "website": "https://localai.io/",
    "slug": "",
    "mostCommonModels": [],
    "uptimeLatencyChartsLink": "",
    "discordCommunityLink": "https://portkey.ai/community",
    "pricingLink": "",
    "documentationLink": "https://localai.io/"
  },
  "supported": {
    "models": [
      {
        "title": "Chat Completions, Reranker, Text-to-Speech, Image Generation, Embeddings, Speech-to-Text",
        "description": "Portkey supports Local AI API through a Post Proxy call. Read more [here](/../link/to/post-proxy-dcoumentation)",
        "supportedModels": [],
        "moreModels": "https://localai.io/gallery.html"
      }
    ],
    "notSupported": {
      "promptPlayground": "Prompt playground is not supported for Inference models",
      "parameters": []
    },
    "integration": {
      "chatCompletionsCall": {
        "portkeyPythonSDK": {
          "description": "Use Portkey Python SDK to make chat calls to Local AI chat completions models",
          "codeExample": "sample python code for llama-3.1 chat call on Local AI"
        },
        "portkeyNodeSDK": {
          "description": "Use Portkey Node.js SDK to make chat calls to Local AI chat completions models",
          "codeExample": "sample node.js code for llama-3.1 chat call on Local AI"
        },
        "restAPI": {
          "description": "Use Portkey's REST API to make chat calls to Local AI chat completions models",
          "codeExample": "sample rest api code for llama-3.1 chat call on Local AI"
        },
        "openAIPythonSDK": {
          "description": "Use OpenAI Python SDK to make chat calls to Local AI chat completions models",
          "codeExample": "sample openai SDK python code for llama-3.1 chat call on Local AI"
        },
        "openAINodeSDK": {
          "description": "Use OpenAI Node.js SDK to make chat calls to Local AI chat completions models",
          "codeExample": "sample openai SDK node.js code for llama-3.1 chat call on Local AI"
        }
      },
      "integrationViaVirtualKey": {
        "description": "",
        "generateVirtualKey": {
          "inline": {
            "text": "",
            "screenshot": "",
            "description": ""
          }
        }
      },
      "promptPlayground": {
        "description": "Coming soon.."
      }
    },
    "specialExamples": [],
    "portkeyCapabilities": [
      {
        "title": "Configure Routing",
        "description": "Configure routing for your Cerebras requests",
        "link": "/docs/product/ai-gateway/routing"
      },
      {
        "title": "Add Metadata to Requests",
        "description": "Add metadata to your Cerebras requests",
        "link": "/docs/product/observability/metadata"
      },
      {
        "title": "A/B Test Different Models",
        "description": "A/B test different models",
        "link": "/docs/product/ai-gateway/load-balance"
      },
      {
        "title": "Gain Insights to Requests",
        "description": "Gain insights to your Cerebras requests",
        "link": "/docs/product/observability/traces"
      }
    ],
    "useCases": [],
    "additionalInfo": []
  }
}
