{
  "provider": {
    "name": "Inference.net",
    "imageUrl": "",
    "description": "Inference is a wholesaler of LLM inference tokens for models like Llama 3.1",
    "website": "https://www.inference.net/",
    "slug": "Inference",
    "mostCommonModels": [],
    "uptimeLatencyChartsLink": "",
    "discordCommunityLink": "https://portkey.ai/community",
    "pricingLink": "",
    "documentationLink": "https://www.inference.net/"
  },
  "supported": {
    "models": [
      {
        "title": "Chat Completions",
        "description": "Portkey supports the chat completions APIs for Inference.",
        "supportedModels": ["LLama-3.1", "Llama-3"],
        "moreModels": "https://www.inference.net/"
      }
    ],
    "notSupported": {
      "promptPlayground": "Prompt playground is not supported for Inference models",
      "parameters": []
    },
    "integration": {
      "chatCompletionsCall": {
        "portkeyPythonSDK": {
          "description": "Use Portkey Python SDK to make chat calls to Inference chat completions models",
          "codeExample": "sample python code for llama-3.1 chat call on Inference"
        },
        "portkeyNodeSDK": {
          "description": "Use Portkey Node.js SDK to make chat calls to Inference chat completions models",
          "codeExample": "sample node.js code for llama-3.1 chat call on Inference"
        },
        "restAPI": {
          "description": "Use Portkey's REST API to make chat calls to Inference chat completions models",
          "codeExample": "sample rest api code for llama-3.1 chat call on Inference"
        },
        "openAIPythonSDK": {
          "description": "Use OpenAI Python SDK to make chat calls to Inference chat completions models",
          "codeExample": "sample openai SDK python code for llama-3.1 chat call on Inference"
        },
        "openAINodeSDK": {
          "description": "Use OpenAI Node.js SDK to make chat calls to Inference chat completions models",
          "codeExample": "sample openai SDK node.js code for llama-3.1 chat call on Inference"
        }
      },
      "integrationViaVirtualKey": {
        "description": "Integrate Inference using Portkey's virtual key system",
        "generateVirtualKey": {
          "inline": {
            "text": "Get your API key from Inference and add it to Portkey to create a virtual key.",
            "screenshot": "insert screenshot here",
            "description": "You can get your Inference API key from the Inference website [here](https://www.inference.net/)."
          }
        },
        "portkeyPythonSDK": {
          "description": "Initialize Portkey with the virtual key in Python",
          "codeExample": "sample python SDK code for llama-3.1 chat completions call on Inference using virtual key"
        },
        "portkeyNodeSDK": {
          "description": "Initialize Portkey with the virtual key in Node.js",
          "codeExample": "sample node.js SDK code for llama-3.1 chat completions call on Inference using virtual key"
        },
        "restAPI": {
          "description": "Use Portkey's REST API to make chat calls to Inference chat completions models like llama-3.1",
          "codeExample": "sample rest api code for llama-3.1 chat completions call on Inference using virtual key"
        },
        "openAIPythonSDK": {
          "description": "Use OpenAI Python SDK to make chat calls to Inference chat completions models like llama-3.1",
          "codeExample": "sample openai SDK python code for llama-3.1 chat completions call on Inference using virtual key"
        },
        "openAINodeSDK": {
          "description": "Use OpenAI Node.js SDK to make chat calls to Inference chat completions models like llama-3.1",
          "codeExample": "sample openai SDK node.js code for llama-3.1 chat completions call on Inference using virtual key"
        }
      },
      "promptPlayground": {
        "description": "Coming soon.."
      }
    },
    "specialExamples": [],
    "portkeyCapabilities": [
      {
        "title": "Configure Routing",
        "description": "Configure routing for your Cerebras requests",
        "link": "/docs/product/ai-gateway/routing"
      },
      {
        "title": "Add Metadata to Requests",
        "description": "Add metadata to your Cerebras requests",
        "link": "/docs/product/observability/metadata"
      },
      {
        "title": "A/B Test Different Models",
        "description": "A/B test different models",
        "link": "/docs/product/ai-gateway/load-balance"
      },
      {
        "title": "Gain Insights to Requests",
        "description": "Gain insights to your Cerebras requests",
        "link": "/docs/product/observability/traces"
      }
    ],
    "useCases": [],
    "additionalInfo": []
  }
}
