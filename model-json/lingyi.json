{
    "provider": {
        "name": "Lingyi (01.ai)",
        "imageUrl": "",
        "description": "Yi Open Source Models",
        "website": "https://platform.lingyiwanwu.com/",
        "slug": "lingyi",
        "mostCommonModels": [
        ],
        "uptimeLatencyChartsLink": "",
        "discordCommunityLink": "https://discord.gg/WWzerjfb",
        "pricingLink": "",
        "documentationLink": "https://github.com/01-ai/Yi-1.5"
    },
    "supported": {
        "models": [
            {
                "title": "Chat Completions",
                "description": "Portkey supports all Open AI compatible chat endpoints for Yi models",
                "supportedModels": [
                    "Yi-Large",
                    "Yi-Large-Turbo",
                    "Yi-Large-FC",
                    "Yi-Large-RAG"
                ],
                "moreModels": "https://platform.lingyiwanwu.com/"
            }
        ],
        "notSupported": {
            "promptPlayground": "Prompt playground is not supported for Yi models"
        },
        
        "integration": {
            "chatCompletionsCall": {
                "portkeyPythonSDK": {
                    "description": "Use Portkey Python SDK to make text calls to Yi chat completions models",
                    "codeExample": "sample python code for Yi-Large text call on Lingyi"
                },
                "portkeyNodeSDK": {
                    "description": "Use Portkey Node.js SDK to make text calls to Yi chat completions models",
                    "codeExample": "sample node.js code for Yi-Large text call on Lingyi"
                },
                "restAPI": {
                    "description": "Use Portkey's REST API to make text calls to Yi chat completions models",
                    "codeExample": "sample rest api code for Yi-Large text call on Lingyi"
                },
                "openAIPythonSDK": {
                    "description": "Use OpenAI Python SDK to make text calls to Yi chat completions models",
                    "codeExample": "sample openai SDK python code for Yi-Large text call on Lingyi"
                },
                "openAINodeSDK": {
                    "description": "Use OpenAI Node.js SDK to make text calls to Yi chat completions models",
                    "codeExample": "sample openai SDK node.js code for Yi-Large text call on Lingyi"
                }
            },
            "integrationViaVirtualKey": {
                "description": "Integrate Lingyi using Portkey's virtual key system",
                "generateVirtualKey": {
                    "inline": {{
    "provider": {
        "name": "Lingyi (01.ai)",
        "imageUrl": "",
        "description": "Yi Open Source Models",
        "website": "https://platform.lingyiwanwu.com/",
        "slug": "lingyi",
        "mostCommonModels": [
        ],
        "uptimeLatencyChartsLink": "",
        "discordCommunityLink": "https://discord.gg/WWzerjfb",
        "pricingLink": "",
        "documentationLink": "https://github.com/01-ai/Yi-1.5"
    },
    "supported": {
        "models": [
            {
                "title": "Chat Completions",
                "description": "Portkey supports all Open AI compatible chat endpoints for Yi models",
                "supportedModels": [
                    "Yi-Large",
                    "Yi-Large-Turbo",
                    "Yi-Large-FC",
                    "Yi-Large-RAG"
                ],
                "moreModels": "https://platform.lingyiwanwu.com/"
            }
        ],
        "notSupported": {
            "promptPlayground": "Prompt playground is not supported for Yi models"
        },
        
        "integration": {
            "chatCompletionsCall": {
                "portkeyPythonSDK": {
                    "description": "Use Portkey Python SDK to make text calls to Yi chat completions models",
                    "codeExample": "sample python code for Yi-Large text call on Lingyi"
                },
                "portkeyNodeSDK": {
                    "description": "Use Portkey Node.js SDK to make text calls to Yi chat completions models",
                    "codeExample": "sample node.js code for Yi-Large text call on Lingyi"
                },
                "restAPI": {
                    "description": "Use Portkey's REST API to make text calls to Yi chat completions models",
                    "codeExample": "sample rest api code for Yi-Large text call on Lingyi"
                },
                "openAIPythonSDK": {
                    "description": "Use OpenAI Python SDK to make text calls to Yi chat completions models",
                    "codeExample": "sample openai SDK python code for Yi-Large text call on Lingyi"
                },
                "openAINodeSDK": {
                    "description": "Use OpenAI Node.js SDK to make text calls to Yi chat completions models",
                    "codeExample": "sample openai SDK node.js code for Yi-Large text call on Lingyi"
                }
            },
            "integrationViaVirtualKey": {
                "description": "Integrate Lingyi using Portkey's virtual key system",
                "generateVirtualKey": {
                    "inline": {
                        "text": "Get your API key from Lingyi and add it to Portkey to create a virtual key.",
                        "screenshot": "insert screenshot here",
                        "description": "You can get your Lingyi API key from the Lingyi website [here](https://platform.lingyiwanwu.com/)."
                    }
                },
                "portkeyPythonSDK": {
                    "description": "Initialize Portkey with the virtual key in Python",
                    "codeExample": "sample python SDK code for Yi-Large chat completions call on Lingyi using virtual key"
                },
                "portkeyNodeSDK": {
                    "description": "Initialize Portkey with the virtual key in Node.js",
                    "codeExample": "sample node.js SDK code for Yi-Large chat completions call on Lingyi using virtual key"
                },
                "restAPI": {
                    "description": "Use Portkey's REST API to make text calls to Lingyi chat completions models like Yi-Large",
                    "codeExample": "sample rest api code for Yi-Large chat completions call on Lingyi using virtual key"
                },
                "openAIPythonSDK": {
                    "description": "Use OpenAI Python SDK to make text calls to Lingyi chat completions models like Yi-Large",
                    "codeExample": "sample openai SDK python code for Yi-Large chat completions call on Lingyi using virtual key"
                },
                "openAINodeSDK": {
                    "description": "Use OpenAI Node.js SDK to make text calls to Lingyi chat completions models like Yi-Large",
                    "codeExample": "sample openai SDK node.js code for Yi-Large chat completions call on Lingyi using virtual key"
                }
            },
            "promptPlayground": {
                "description": "Coming soon.."
            }
        },
        "specialExamples": [
        ],
        "portkeyCapabilities": [
            {
                "title": "Configure Routing",
                "description": "Configure routing for your Lingyi requests",
                "link": "/docs/product/ai-gateway/routing"
            },
            {
                "title": "Add Metadata to Requests",
                "description": "Add metadata to your Lingyi requests",
                "link": "/docs/product/observability/metadata"
            },
            {
                "title": "A/B Test Different Models",
                "description": "A/B test different models",
                "link": "/docs/product/ai-gateway/load-balance"
            },
            {
                "title": "Gain Insights to Requests",
                "description": "Gain insights to your Lingyi requests",
                "link": "/docs/product/observability/traces"
            }
        ],
        "useCases": [],
        "additionalInfo": []
    }
}
                        "text": "Get your API key from Lingyi and add it to Portkey to create a virtual key.",
                        "screenshot": "insert screenshot here",
                        "description": "You can get your Lingyi API key from the Lingyi website [here](https://platform.lingyiwanwu.com/)."
                    }
                },
                "portkeyPythonSDK": {
                    "description": "Initialize Portkey with the virtual key in Python",
                    "codeExample": "sample python SDK code for Yi-Large chat completions call on Lingyi using virtual key"
                },
                "portkeyNodeSDK": {
                    "description": "Initialize Portkey with the virtual key in Node.js",
                    "codeExample": "sample node.js SDK code for Yi-Large chat completions call on Lingyi using virtual key"
                },
                "restAPI": {
                    "description": "Use Portkey's REST API to make text calls to Lingyi chat completions models like Yi-Large",
                    "codeExample": "sample rest api code for Yi-Large chat completions call on Lingyi using virtual key"
                },
                "openAIPythonSDK": {
                    "description": "Use OpenAI Python SDK to make text calls to Lingyi chat completions models like Yi-Large",
                    "codeExample": "sample openai SDK python code for Yi-Large chat completions call on Lingyi using virtual key"
                },
                "openAINodeSDK": {
                    "description": "Use OpenAI Node.js SDK to make text calls to Lingyi chat completions models like Yi-Large",
                    "codeExample": "sample openai SDK node.js code for Yi-Large chat completions call on Lingyi using virtual key"
                }
            },
            "promptPlayground": {
                "description": "Coming soon.."
            }
        },
        "specialExamples": [
        ],
        "portkeyCapabilities": [
            {
                "title": "Configure Routing",
                "description": "Configure routing for your Lingyi requests",
                "link": "/docs/product/ai-gateway/routing"
            },
            {
                "title": "Add Metadata to Requests",
                "description": "Add metadata to your Lingyi requests",
                "link": "/docs/product/observability/metadata"
            },
            {
                "title": "A/B Test Different Models",
                "description": "A/B test different models",
                "link": "/docs/product/ai-gateway/load-balance"
            },
            {
                "title": "Gain Insights to Requests",
                "description": "Gain insights to your Lingyi requests",
                "link": "/docs/product/observability/traces"
            }
        ],
        "useCases": [],
        "additionalInfo": []
    }
}