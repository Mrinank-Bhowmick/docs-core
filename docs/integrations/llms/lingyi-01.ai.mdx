---
title: 'Lingyi (01.ai)'
description: 'Integrate Yi Open Source Models into your applications with Portkey'
---

**Portkey Provider Slug:** `lingyi`

## Overview

Lingyi (01.ai) provides Yi Open Source Models for developers to build AI-powered applications. This document outlines the features, supported models, and integration methods available for Lingyi through the Portkey platform.

## Quick Links

- [Lingyi Website](https://platform.lingyiwanwu.com/)
- [Documentation](https://github.com/01-ai/Yi-1.5)
- [Community](https://discord.gg/WWzerjfb)

## Supported Features

### Supported Models

| Type | Models |
|------|--------|
| Chat Completions | Yi-Large, Yi-Large-Turbo, Yi-Large-FC, Yi-Large-RAG |

Portkey supports all Open AI compatible chat endpoints for Yi models.

[More models](https://platform.lingyiwanwu.com/)

### Unsupported Features

- **Prompt Playground**: Prompt playground is not supported for Yi models

## Integration Guide

### Chat Completions Calls

<CodeGroup>

```Python python
# Use Portkey Python SDK to make text calls to Yi chat completions models
# Sample Python code for Yi-Large text call on Lingyi
# Code example to be added
```

```Node node
// Use Portkey Node.js SDK to make text calls to Yi chat completions models
// Sample Node.js code for Yi-Large text call on Lingyi
// Code example to be added
```

```bash cURL
# Use Portkey's REST API to make text calls to Yi chat completions models
# Sample REST API code for Yi-Large text call on Lingyi
# Code example to be added
```

```Python OpenAI Python SDK
# Use OpenAI Python SDK to make text calls to Yi chat completions models
# Sample OpenAI SDK Python code for Yi-Large text call on Lingyi
# Code example to be added
```

```Node OpenAI Node SDK
// Use OpenAI Node.js SDK to make text calls to Yi chat completions models
// Sample OpenAI SDK Node.js code for Yi-Large text call on Lingyi
// Code example to be added
```

</CodeGroup>

### Integration via Virtual Key

1. **Generate a Virtual Key**
   Get your API key from Lingyi and add it to Portkey to create a virtual key.

   You can get your Lingyi API key from the Lingyi website [here](https://platform.lingyiwanwu.com/).

   [Insert screenshot of virtual key generation process here]

2. **Using the Virtual Key**

<CodeGroup>

```Python python
# Initialize Portkey with the virtual key in Python
# Sample Python SDK code for Yi-Large chat completions call on Lingyi using virtual key
# Code example to be added
```

```Node node
// Initialize Portkey with the virtual key in Node.js
// Sample Node.js SDK code for Yi-Large chat completions call on Lingyi using virtual key
// Code example to be added
```

```bash cURL
# Use Portkey's REST API to make text calls to Lingyi chat completions models like Yi-Large
# Sample REST API code for Yi-Large chat completions call on Lingyi using virtual key
# Code example to be added
```

```Python OpenAI Python SDK
# Use OpenAI Python SDK to make text calls to Lingyi chat completions models like Yi-Large
# Sample OpenAI SDK Python code for Yi-Large chat completions call on Lingyi using virtual key
# Code example to be added
```

```Node OpenAI Node SDK
// Use OpenAI Node.js SDK to make text calls to Lingyi chat completions models like Yi-Large
// Sample OpenAI SDK Node.js code for Yi-Large chat completions call on Lingyi using virtual key
// Code example to be added
```

</CodeGroup>

### Prompt Playground

Coming soon...

## Explore Advanced Portkey Features

<CardGroup cols={2}>
  <Card title="Configure Routing" href="/docs/product/ai-gateway/routing">
    <img src="/api/placeholder/400/320" alt="Configure Routing" />
  </Card>
  <Card title="Add Metadata to Requests" href="/docs/product/observability/metadata">
    <img src="/api/placeholder/400/320" alt="Add Metadata to Requests" />
  </Card>
  <Card title="A/B Test Different Models" href="/docs/product/ai-gateway/load-balance">
    <img src="/api/placeholder/400/320" alt="A/B Test Different Models" />
  </Card>
  <Card title="Gain Insights to Requests" href="/docs/product/observability/traces">
    <img src="/api/placeholder/400/320" alt="Gain Insights to Requests" />
  </Card>
</CardGroup>