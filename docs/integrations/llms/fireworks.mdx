---
title: 'Fireworks'
description: 'Integrate Fireworks AI LLMs into your applications with Portkey'
---

**Portkey Provider Slug:** `fireworks-ai`

## Overview

Fireworks AI is a generative AI inference platform to run and customize models. This document outlines the features, supported models, and integration methods available for Fireworks through the Portkey platform.

## Quick Links

- [Fireworks Website](https://fireworks.ai/)
- [Pricing](https://fireworks.ai/pricing)
- [Documentation](https://docs.fireworks.ai/getting-started/introduction)
- [Community](https://discord.com/invite/fireworks-ai)

## Supported Features

### Supported Models

| Type | Description |
|------|-------------|
| Chat Completions | Portkey supports majority of chat models offered by Fireworks |
| Embed | Portkey supports majority of embed models offered by Fireworks |
| Vision | Portkey supports majority of vision models offered by Fireworks |

[View all models](https://fireworks.ai/models)

**Note:** Fireworks model names generally have `accounts/fireworks/models/` prefix. For example, to use llama-v3p1-405b-instruct, you need to pass `accounts/fireworks/models/llama-v3p1-405b-instruct` as the model name.

### Unsupported Features

- **Speech**: Portkey currently doesn't support any speech endpoints by Fireworks

### Fireworks-Specific Features

- **Function Calling**: The function calling API allows a user to describe the set of tools/functions available to the model and have the model intelligently choose the right set of function calls to invoke given the context. [Learn more](https://docs.fireworks.ai/guides/function-calling)

- **Grammar Mode**: Grammar mode is the ability to specify a forced output schema for any Fireworks model via an extended BNF formal grammar (GBNF format). [Learn more](https://docs.fireworks.ai/structured-responses/structured-output-grammar-based)

- **JSON Mode**: JSON mode enables you to provide a JSON schema to force any Fireworks language model to respond in. [Learn more](https://docs.fireworks.ai/structured-responses/structured-response-formatting)

## Integration Guide

### Chat Completions Calls

<CodeGroup>

```Python python
# Use Portkey Python SDK to make text calls to Fireworks chat completions models
# Sample Python code for llama-v3p1-405b-instruct call on Fireworks
# Code example to be added
```

```Node node
// Use Portkey Node.js SDK to make text calls to Fireworks chat completions models
// Sample Node.js code for llama-v3p1-405b-instruct call on Fireworks
// Code example to be added
```

```bash cURL
# Use Portkey's REST API to make text calls to Fireworks chat completions models
# Sample REST API code for llama-v3p1-405b-instruct text call on Fireworks
# Code example to be added
```

```Python OpenAI Python SDK
# Use OpenAI Python SDK to make text calls to Fireworks chat completions models
# Sample OpenAI SDK Python code for llama-v3p1-405b-instruct text call on Fireworks
# Code example to be added
```

```Node OpenAI Node SDK
// Use OpenAI Node.js SDK to make text calls to Fireworks chat completions models
// Sample OpenAI SDK Node.js code for llama-v3p1-405b-instruct text call on Fireworks
// Code example to be added
```

</CodeGroup>

### Integration via Virtual Key

1. **Generate a Virtual Key**
   Get your API key from Fireworks and add it to Portkey to create a virtual key.

   You can get your Fireworks API key from the Fireworks website [here](https://fireworks.ai/login).

   [Insert screenshot of virtual key generation process here]

2. **Using the Virtual Key**

<CodeGroup>

```Python python
# Initialize Portkey with the virtual key in Python
# Sample Python SDK code for llama-v3p1-405b-instruct chat completions call on Fireworks using virtual key
# Code example to be added
```

```Node node
// Initialize Portkey with the virtual key in Node.js
// Sample Node.js SDK code for llama-v3p1-405b-instruct chat completions call on Fireworks using virtual key
// Code example to be added
```

```bash cURL
# Use Portkey's REST API to make text calls to Fireworks chat completions models like llama-v3p1-405b-instruct
# Sample REST API code for llama-v3p1-405b-instruct chat completions call on Fireworks using virtual key
# Code example to be added
```

```Python OpenAI Python SDK
# Use OpenAI Python SDK to make text calls to Fireworks chat completions models like llama-v3p1-405b-instruct
# Sample OpenAI SDK Python code for llama-v3p1-405b-instruct chat completions call on Fireworks using virtual key
# Code example to be added
```

```Node OpenAI Node SDK
// Use OpenAI Node.js SDK to make text calls to Fireworks chat completions models like llama-v3p1-405b-instruct
// Sample OpenAI SDK Node.js code for llama-v3p1-405b-instruct chat completions call on Fireworks using virtual key
// Code example to be added
```

</CodeGroup>

### Prompt Playground

Manage and test prompts for Fireworks models in the Prompt Library.

[Insert screenshot of Prompt Playground here]

#### Using Prompts from the Prompt Library

<CodeGroup>

```Python python
# Use prompts from the Prompt Library in Python
# Sample Python SDK code for using prompts from the Prompt Library on Fireworks
# Code example to be added
```

```Node node
// Use prompts from the Prompt Library in Node.js
// Sample Node.js SDK code for using prompts from the Prompt Library on Fireworks
// Code example to be added
```

```bash cURL
# Use Portkey's REST API to manage and test prompts for Fireworks models in the Prompt Library
# Sample REST API code for using prompts from the Prompt Library on Fireworks
# Code example to be added
```

```Python OpenAI Python SDK
# Not supported
```

```Node OpenAI Node SDK
// Not supported
```

</CodeGroup>

## Special Examples

### Using Vision Models

<CodeGroup>

```Python python
# Make a call to Fireworks vision models
# Sample Python SDK code for vision models on Fireworks
# Code example to be added
```

```Node node
// Make a call to Fireworks vision models
// Sample Node.js SDK code for vision models on Fireworks
// Code example to be added
```

```bash cURL
# Use Portkey's REST API to make a call to Fireworks vision models
# Sample REST API code for vision models on Fireworks
# Code example to be added
```

```Python OpenAI Python SDK
# Using OpenAI Python SDK to make a call to Fireworks vision models
# Sample OpenAI Python SDK code for vision models on Fireworks
# Code example to be added
```

```Node OpenAI Node SDK
// Using OpenAI Node.js SDK to make a call to Fireworks vision models
// Sample OpenAI Node.js SDK code for vision models on Fireworks
// Code example to be added
```

</CodeGroup>

### Using Image Generation Models

<CodeGroup>

```Python python
# Make a call to Fireworks image generation models
# Sample Python SDK code for image generation models on Fireworks
# Code example to be added
```

```Node node
// Make a call to Fireworks image generation models
// Sample Node.js SDK code for image generation models on Fireworks
// Code example to be added
```

```bash cURL
# Use Portkey's REST API to make a call to Fireworks image generation models
# Sample REST API code for image generation models on Fireworks
# Code example to be added
```

```Python OpenAI Python SDK
# Using OpenAI Python SDK to make a call to Fireworks vision models
# Sample OpenAI Python SDK code for vision models on Fireworks
# Code example to be added
```

```Node OpenAI Node SDK
// Using OpenAI Node.js SDK to make a call to Fireworks image generation models
// Sample OpenAI Node.js SDK code for image generation models on Fireworks
// Code example to be added
```

</CodeGroup>

### Fireworks Grammar Mode

**Note:** Fireworks Grammar Mode is not supported on Portkey prompts playground

<CodeGroup>

```Python python
# Make a call to Fireworks Grammar Mode
# Sample Python SDK code for Grammar Mode on Fireworks
# Code example to be added
```

```Node node
// Make a call to Fireworks Grammar Mode
// Sample Node.js SDK code for Grammar Mode on Fireworks
// Code example to be added
```

```bash cURL
# Use Portkey's REST API to make a call to Fireworks Grammar Mode
# Sample REST API code for Grammar Mode on Fireworks
# Code example to be added
```

```Python OpenAI Python SDK
# Using OpenAI Python SDK to make a call to Fireworks Grammar Mode
# Sample OpenAI Python SDK code for Grammar Mode on Fireworks
# Code example to be added
```

```Node OpenAI Node SDK
// Using OpenAI Node.js SDK to make a call to Fireworks Grammar Mode
// Sample OpenAI Node.js SDK code for Grammar Mode on Fireworks
// Code example to be added
```

</CodeGroup>

### Fireworks JSON Mode

**Note:** Fireworks JSON Mode is not supported on Portkey prompts playground

<CodeGroup>

```Python python
# Make a call to Fireworks JSON Mode
# Sample Python SDK code for JSON Mode on Fireworks
# Code example to be added
```

```Node node
// Make a call to Fireworks JSON Mode
// Sample Node.js SDK code for JSON Mode on Fireworks
// Code example to be added
```

```bash cURL
# Use Portkey's REST API to make a call to Fireworks JSON Mode
# Sample REST API code for JSON Mode on Fireworks
# Code example to be added
```

```Python OpenAI Python SDK
# Using OpenAI Python SDK to make a call to Fireworks JSON Mode
# Sample OpenAI Python SDK code for JSON Mode on Fireworks
# Code example to be added
```

```Node OpenAI Node SDK
// Using OpenAI Node.js SDK to make a call to Fireworks JSON Mode
// Sample OpenAI Node.js SDK code for JSON Mode on Fireworks
// Code example to be added
```

</CodeGroup>

## Explore Advanced Portkey Features

<CardGroup cols={2}>
  <Card title="Configure Routing" href="/docs/product/ai-gateway/routing">
    <img src="/api/placeholder/400/320" alt="Configure Routing" />
  </Card>
  <Card title="Add Metadata to Requests" href="/docs/product/observability/metadata">
    <img src="/api/placeholder/400/320" alt="Add Metadata to Requests" />
  </Card>
  <Card title="A/B Test Different Models" href="/docs/product/ai-gateway/load-balance">
    <img src="/api/placeholder/400/320" alt="A/B Test Different Models" />
  </Card>
  <Card title="Gain Insights to Requests" href="/docs/product/observability/traces">
    <img src="/api/placeholder/400/320" alt="Gain Insights to Requests" />
  </Card>
</CardGroup>